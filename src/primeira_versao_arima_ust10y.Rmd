---
title: "Trabalho final MAE4000"
output:
  html_document:
    df_print: paged
---

Primeiro vamos carregar os pacotes desejados:

```{r}

rm(list=ls())
library("dplyr")
library("tidyr")
library("readxl")
library("data.table")
library("here")
library("ggplot2")
library("reshape2")
library("lubridate")
library("readr")
library("tseries")
library("fpp2")
library("padr")
library("TSA")
library("prophet")
library("ggpubr")

```

Uma vez com os pacotes carregados, podemos agora carregar e plotar os dados desejados:

## desde 2000, dados mensais

```{r}

dados <- read_delim(here("src", "data", "curva_juros_nominal_us.txt"),
                    delim = "\t",
                    escape_double = FALSE, 
                    trim_ws = TRUE) %>% as.data.table() %>% rename(date=Dates) %>% filter(date>="2000-01-01")


weekly_dados = dados %>% mutate(date=ymd(date)) %>% pad() %>%
  fill(`USGG2YR Index`, `USGG5YR Index`, `USGG10YR Index`, `USGG30YR Index`, .direction=c("down")) %>%
  mutate(weekday=weekdays(date, abbreviate = TRUE)) %>% filter(weekday=='Sex'|weekday=='Fri') %>%
  select(-weekday)

```

Os dados consistêm de alguns vértices da curva de juros nominal dos Estados Unidos. Os vérties do juros nominal de cinco (USGG5YR) e dez (USGG10YR) anos possuem observações desde 1970, já os vértices de dois (USGG2YR) e 30 (USGG30YR) anos começam em 1977.

```{r}

head(weekly_dados)

```


```{r}

head(dados %>% drop_na())

```
No código abaixo, podemos ver o gráfico dos vértices ao longo do tempo:

```{r}

melt_dados <- melt(weekly_dados %>% drop_na(), id="date")
ggplot(melt_dados, aes(x=date, y=value, colour=variable, group=variable)) + geom_line()

```
No que se segue, analisaremos o véritce de dez anos.

Começamos nossa análise testando a hipótese de estacionariedade da série em questão. Para tanto, usaremos a definição de Shumway e Stoffer (2016) que caracteriza um processo estacionário da seguinte forma:

>> 1) A função de média do processo não depende de $t$
>> 2) A função de autocovariância do processo depende do tempo somente através da diferença de $|s - t|$

A inspeção visual da série em questão parece indicar que a média da série varia no tempo. Apesar disso, usaremos dois testes de hipótese para identificar raiz unitária no processo, sendo eles o deste de Dickey-Fuller e o teste de Phillips–Perron.


```{r}

target_data = weekly_dados %>% select(date, `USGG10YR Index`)
colnames(target_data) = c("date", "USGG10YR")

ggplot(target_data, aes(x=date, y=USGG10YR)) + geom_line() + xlab("")

```

Como podemos ver, ambos os testes não rejeitam a hipótese nula de raiz unitária, portando precisaremos aplicar alguma trasformação nos dados. 

```{r}

adf.test(target_data %>% select(USGG10YR) %>% as.ts())

```

```{r}

PP.test(target_data %>% select(USGG10YR) %>% as.ts())

```

Uma alternativa é aplicar a primeira diferença na série. Podemos notar que ao aplicarmos a primeira diferença, ambos os testes rejeitam a hipótese de raiz unitária do processo diferenciado. Deste modo, seguiremos a análise com o processo em primeira diferença.

```{r}

adf.test(target_data %>% select(USGG10YR) %>% as.ts() %>% diff())

```

```{r}

PP.test(target_data %>% select(USGG10YR) %>% as.ts() %>% diff())

```


```{r}

diff_target_data = target_data %>% mutate(USGG10YR_diff=diff(c(NA, USGG10YR))) %>%
  select(date, USGG10YR_diff) %>% drop_na()

USGG10YR_diff_ts = as.ts(diff_target_data$USGG10YR_diff)

ggplot(diff_target_data, aes(x=date, y=USGG10YR_diff)) + geom_line() + xlab("")

```
Como primeira forma de identificar o modelo ideal para a série do juros de 10 anos, seguiremos Shumway e Stoffer (2016) e usaremos a função de autocorrelação (ACF) e autocorrelação parcial (PACF) para identificar os parâmetros de um modelo ARMA(p,q).

Podemos notar, como ambas as ACF e PACF tem padrões similares de um segunda lag significativo, um bom candidato de modelo seria um ARMA(2, 2). Iremos testar esta hipótese de algumas formas diferentes nos passos abaixo.


```{r}

ggAcf(USGG10YR_diff_ts)

```


```{r}

ggPacf(USGG10YR_diff_ts)

```

Uma vez com o primeiro especificação de modelo em mãos, usaremos o critério de informação de Akaike (AIC) e bayesiano (BIC) para identifcar se existe um modelo mais parsimonioso para o processo gerador de dados. Avaliaremos ambos os critérios para ARMA(p, q), onde $p \in {1, 2, 3, 4}$ e $q=0$.

Notamos que para o critério AIC, o modelo escolhido é um ARIMA(4, 0, 3), já para o critério BIC o modelo escolhido é o ARMA(1, 0, 1). Estimaremos os dois modelos e continuaremos a análise a partir deles.

Como terceira forma de escolher o modelo ARMA que melhor se ajusta aos dados, utilizamos a função "auto.arima" do pacote "forecast". Esta função retorna o melhor modelo ARIMA de acordo com o critério de informação disponível. Notamos que o modelo escolhido é ainda diferente do escolhido pelos métodos anteriores, sendo ele um ARMA(2, 2).

```{r}

aic = list()
bic = list()
q = 0

for (p in 1:4){
  for (q in 1:4){
    tmp_arma = arima(USGG10YR_diff_ts, order=c(p, 0, q))
  
    aic[[paste0(p, "_", q)]] = AIC(tmp_arma)
    bic[[paste0(p, "_", q)]] = BIC(tmp_arma) 
  }
}

information_df = cbind(do.call("rbind", aic) %>% as.data.table(),
                       do.call("rbind", bic) %>% as.data.table())
colnames(information_df) = c("AIC", "BIC")
information_df$models = names(aic)
information_df = information_df %>% select(models, everything())

information_df
min(information_df$AIC)
min(information_df$BIC)
```

```{r}

auto_arima <- auto.arima(y = USGG10YR_diff_ts,
                         max.p = 4,
                         max.q = 4,
                         allowmean = TRUE)


summary(auto_arima)

```

```{r}

arima_aic <- arima(USGG10YR_diff_ts, order=c(4, 0, 3))
arima_bic <- arima(USGG10YR_diff_ts, order=c(1, 0, 1))
arima_auto <- arima(USGG10YR_diff_ts, order=c(2, 0, 2))

```



Uma vez com os modelos em mãos, avaliaremos abaixo os modelos ajustados, isto é, avaliaremos as estatísticas de ajuste de modelos bem como o resíduo destes. Para fins de simplificação, chamaremos o modelo ARMA(4, 4) de modelo A, o modelo ARIMA (1, 1) de modelo B e, por fim, o modelo ARMA(2, 2) de modelo C.

Notamos que tanto em termos de log-verossimilhança quanto AIC, o modelo A tem o melhor ajuste. Além disso, ambos os resíduos apresentam problemas. Os resíduos de ambas as séries rejeitam fortemente a hipótese nula de normalidade dos dados. Outro ponto de atenção é que ambos os resíduos apresentam lags significativos na ACF.

(...)


```{r}

resid_aic = arima_aic$residuals %>% as.data.table()
colnames(resid_aic) = c("AIC_resid")
resid_aic$date = diff_target_data$date
resid_aic = resid_aic %>% select(date, everything())

summary(arima_aic)
coefs_aic <- append(1, as.vector(arima_aic$coef * -1)) 
roots_aic <- polyroot(coefs_aic) %>% as.data.table()
roots_aic %>% mutate(coef_name=names(arima_aic$coef), t_ratio=arima_aic$coef / sqrt(diag(vcov(arima_aic)))) %>%
  rename(roots=x) %>% select(coef_name, everything())
ggqqplot(arima_aic$residuals)
ggplot(resid_aic, aes(x=date, y=AIC_resid)) + geom_line() + xlab("")
ggAcf(resid_aic$AIC_resid)
ggPacf(resid_aic$AIC_resid)

```


```{r}

resid_bic = arima_bic$residuals %>% as.data.table()
colnames(resid_bic) = c("BIC_resid")
resid_bic$date = diff_target_data$date
resid_bic = resid_bic %>% select(date, everything())

summary(arima_bic)
coefs_bic <- append(1, as.vector(arima_bic$coef * -1)) 
roots_bic <- polyroot(coefs_bic) %>% as.data.table()
roots_bic %>% mutate(coef_name=names(arima_bic$coef), t_ratio=arima_bic$coef / sqrt(diag(vcov(arima_bic)))) %>%
  rename(roots=x) %>% select(coef_name, everything())
ggqqplot(arima_bic$residuals)
ggplot(resid_bic, aes(x=date, y=BIC_resid)) + geom_line() + xlab("")
ggAcf(resid_bic$BIC_resid)
ggPacf(resid_bic$BIC_resid)

```


```{r}

resid_auto = arima_auto$residuals %>% as.data.table()
colnames(resid_auto) = c("AIC_auto")
resid_auto$date = diff_target_data$date
resid_auto = resid_auto %>% select(date, everything())

summary(arima_auto)
coefs_auto <- append(1, as.vector(arima_auto$coef * -1)) 
roots_auto <- polyroot(coefs_auto) %>% as.data.table()
roots_auto %>% mutate(coef_name=names(arima_auto$coef), t_ratio=arima_auto$coef / sqrt(diag(vcov(arima_auto)))) %>%
  rename(roots=x) %>% select(coef_name, everything())
ggqqplot(arima_auto$residuals)
ggplot(resid_auto, aes(x=date, y=AIC_auto)) + geom_line() + xlab("")
ggAcf(resid_auto$AIC_auto)
ggPacf(resid_auto$AIC_auto)

```

Como forma de melhorar as propriedades dos modelos apresentados acima, utilizaremos duas variáveis consideradas relevantes na literatura economica, a expectativa de inflação e atividade representada pela mediana das projeções dos principais economistas de mercado para estas variáveis.

Abaixo plotaremos essas variáveis:

```{r}

expectations <- read_delim(here("src", "data", "gdp_cpi_expect_us.txt"),
                           delim = "\t",
                           escape_double = FALSE, 
                           trim_ws = TRUE) %>% as.data.table()


weekly_expectations = expectations %>% mutate(date=ymd(date)) %>% pad() %>%
  fill(ECGDUS, ECPIUS, .direction=c("down")) %>%
  mutate(weekday=weekdays(date, abbreviate = TRUE)) %>% filter(weekday=='Sex'|weekday=='Fri') %>%
  select(-weekday)

melt_expectations <- melt(weekly_expectations %>% drop_na(), id="date")
ggplot(melt_expectations, aes(x=date, y=value, colour=variable, group=variable)) + geom_line()

```

Novamente notamos que as variáveis são não estacionárias, então aplicaremos a primeira diferença nestas para conseguirmos utilizar na modelagem.

```{r}

diff_expectations = expectations %>% mutate(ECGDUS=c(NA, diff(ECGDUS)), ECPIUS=c(NA, diff(ECPIUS))) %>%
  select(date, ECGDUS, ECPIUS) %>% drop_na()

ggplot(melt(diff_expectations %>% drop_na(), id="date"),
       aes(x=date, y=value, colour=variable, group=variable)) + geom_line()

```



```{r}

all_data = merge(diff_target_data, diff_expectations, "date") %>% as.data.table() %>% drop_na()

auto_arimax <- auto.arima(y = all_data %>% select(USGG10YR_diff) %>% as.ts(),
                          max.p = 10,
                          max.q = 10,
                          xreg = all_data %>% select(ECGDUS, ECPIUS) %>% as.ts(),
                     \
                     ]allowmean = TRUE)

resid_x = auto_arimax$residuals %>% as.data.table()
colnames(resid_x) = c("X_resid")
resid_x$date = all_data$date
resid_x = resid_x %>% select(date, everything())

summary(auto_arimax)
shapiro.test(auto_arimax$residuals)
ggplot(resid_x, aes(x=date, y=X_resid)) + geom_line() + xlab("")
ggAcf(auto_arimax$residuals)

```
## FORECAST

```{r}

```




